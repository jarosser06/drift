# Drift Rules File - Consolidated by Resource Type
# Validation rules for the Drift project
#
# ORGANIZATION: Rules are organized by resource type (skills, agents, commands, etc.)
# Each rule contains multiple phases that validate different aspects of that resource type.
# This structure makes it easier to understand what's validated for each resource at a glance.

# ==============================================================================
# SKILL VALIDATION
# ==============================================================================
skill_validation:
  description: "Comprehensive validation for Claude Code skills"
  scope: project_level
  context: "Skills must be well-structured, discoverable, and maintainable. This rule validates file format, frontmatter, content quality, and dependencies."
  requires_project_context: true
  supported_clients:
    - claude-code
  document_bundle:
    bundle_type: skill
    file_patterns:
      - .claude/skills/*/SKILL.md
    bundle_strategy: individual
    resource_patterns:
      - "**/*.py"
      - "**/*.js"
      - "**/*.ts"
  phases:
    # Phase 1: File existence and naming
    - name: check_file_exists
      type: core:file_exists
      params:
        file_path: .claude/skills/*/SKILL.md
      failure_message: "Found skill directory with skill.md (lowercase) instead of SKILL.md (uppercase)"
      expected_behavior: "All skill directories should contain SKILL.md (uppercase) as the main skill file"

    # Phase 2: Frontmatter validation
    - name: check_frontmatter_required_fields
      type: core:yaml_frontmatter
      params:
        required_fields:
          - name
          - description
      failure_message: "Skill frontmatter must include 'name' and 'description' fields"
      expected_behavior: "All skills must have valid YAML frontmatter with 'name' and 'description' fields"

    # Phase 3: Line count validation
    - name: check_line_count
      type: core:file_size
      params:
        max_count: 500
      failure_message: "Skill file exceeds 500 lines - consider splitting into multiple resource files"
      expected_behavior: "Skill files should be <= 500 lines for maintainability"

    # Phase 4: Description quality
    - name: check_description_quality
      type: prompt
      model: sonnet
      prompt: |
        Evaluate the skill description for quality and clarity.

        CRITICAL ISSUES to report:
        - Vague or generic descriptions lacking specificity
        - Missing activation context (when/why to use this skill)
        - No domain-specific terminology or trigger terms

        ACCEPTABLE patterns:
        - Action-oriented language describing what it does
        - Specific mentions of domains, tools, or technologies
        - Clear usage context for skills ("Use when...")

        Examples of GOOD descriptions:
        - Skills: "Expert in pytest test suite creation with 90%+ coverage requirements"
        - "Expert in writing PEP 257 compliant docstrings using Google-style format"
        - "Expert in GitHub workflows including issue management and PR operations"

        Examples of BAD descriptions:
        - "Helps with testing" (too vague)
        - "Does stuff" (no specificity)
        - "A useful tool" (generic, no activation context)

        Only report CRITICAL issues. Ignore minor style preferences.
      available_resources:
        - skill

    # Phase 5: Structural quality
    - name: check_structural_quality
      type: prompt
      model: sonnet
      prompt: |
        Evaluate if skill provides adequate HOW-TO guidance (not WHAT standards).

        A GOOD skill includes:
        - Clear workflows and step-by-step processes
        - Concrete examples showing HOW to do things
        - Tool usage patterns and commands
        - Techniques and best practices for implementation
        - Pure capability/workflow content

        CRITICAL ISSUES (report these):
        - Skill contains MUST/MUST NOT declarations (should be in .claude/rules/)
        - Skill defines quality thresholds or standards (should be in .claude/rules/)
        - Skill has no actionable HOW-TO instructions (only rules/standards)

        ACCEPTABLE (do NOT report):
        - Practical examples showing technique application
        - Workflow descriptions
        - Tool usage instructions
        - "Here's how to..." language
        - Code examples and patterns

        Focus: Does the skill teach HOW to do things, or define WHAT standards must be met?
      available_resources:
        - skill

    # Phase 6: Verify dependencies
    - name: verify_dependencies
      type: prompt
      model: sonnet
      prompt: |
        Check if the skill frontmatter declares dependencies on other skills that don't exist.

        Project context includes MCP servers that are configured. If an MCP server is listed in project context, assume its tools exist.

        ONLY report:
        - Frontmatter declares "dependencies: [skill-name]" but skill-name doesn't exist in .claude/skills/
        - References to MCP servers that are NOT in the project context

        DO NOT check or report:
        - Markdown links (documentation, not dependencies)
        - Relative file paths (resources/file.md is correct)
        - References to project files or scripts
        - MCP tool function names or syntax (e.g., mcp__github__get_issue is valid)
        - Specific MCP tool commands if the server is configured

        Example: If project context shows "MCP Servers: github, serena", then mcp__github__ and mcp__serena__ tool references are valid.

        Focus: Do frontmatter skill dependencies exist? Are MCP servers configured?
      available_resources:
        - skill

    # Phase 7: Check broken links
    - name: check_broken_links
      type: core:markdown_link
      description: "Check for broken links in skill documentation"
      failure_message: "Found broken links in skills"
      expected_behavior: "All file references and links should be valid"
      params:
        check_local_files: true
        check_external_urls: false
        skip_code_blocks: true
        custom_skip_patterns:
          - '\.py'
          - '\.yaml'
          - '\.yml'
          - '\.cfg'
          - '\.json'  # Skip JSON files (often placeholders like log.json)
          - 'CHANGELOG\.md'
          - 'github/workflows/'

    # Phase 8: Check duplicate dependencies
    - name: check_duplicate_dependencies
      type: core:dependency_duplicate
      description: "Check for redundant transitive dependencies in skills"
      failure_message: "Found redundant dependency: {duplicate_resource}"
      expected_behavior: "Skills should only declare direct dependencies, not transitive ones"
      params:
        resource_dirs:
          - .claude/skills

    # Phase 9: Check circular dependencies
    - name: check_circular_dependencies
      type: core:circular_dependencies
      description: "Check for circular dependencies in skill dependency graphs"
      failure_message: "Circular dependency detected: {circular_path}"
      expected_behavior: "Skills should not have circular dependency cycles"
      params:
        resource_dirs:
          - .claude/skills

    # Phase 10: Check max dependency depth
    - name: check_max_dependency_depth
      type: core:claude_max_dependency_depth
      description: "Ensure dependencies don't exceed maximum depth"
      params:
        max_depth: 3
        resource_dirs:
          - .claude/commands
          - .claude/skills
          - .claude/agents
      failure_message: "Dependency depth {actual_depth} exceeds maximum {max_depth}"
      expected_behavior: "Skill dependencies should not exceed depth of 3"

    # Phase 10: Final quality check
    - name: final_quality_check
      type: prompt
      model: sonnet
      prompt: |
        Review all findings from previous validation phases for this skill.

        ONLY report if there are CRITICAL structural problems that would prevent the skill from functioning:
        - Missing required frontmatter fields
        - Broken references to non-existent dependencies
        - Contradictory instructions
        - Completely missing or empty required sections

        IGNORE and do NOT report:
        - Minor formatting preferences
        - Style suggestions
        - Optional improvements
        - Subjective quality opinions

        If all critical issues were already caught by earlier phases, report: "No additional critical issues found."
      available_resources:
        - skill

# ==============================================================================
# AGENT VALIDATION
# ==============================================================================
agent_validation:
  description: "Comprehensive validation for Claude Code agents"
  scope: project_level
  context: "Agents must be well-structured, properly delegated, and maintainable. This rule validates frontmatter, content quality, and dependencies."
  requires_project_context: true
  supported_clients:
    - claude-code
  document_bundle:
    bundle_type: agent
    file_patterns:
      - .claude/agents/*.md
    bundle_strategy: individual
    resource_patterns: []
  phases:
    # Phase 1: Frontmatter validation
    - name: check_frontmatter
      type: core:yaml_frontmatter
      params:
        required_fields:
          - name
          - description
          - model
        schema:
          type: object
          properties:
            name:
              type: string
              pattern: "^[a-z][a-z0-9-]*$"
              description: "Agent name must be lowercase with hyphens"
            description:
              type: string
              minLength: 10
              description: "Agent description must be at least 10 characters"
            model:
              type: string
              enum: ["sonnet", "opus", "haiku", "inherit"]
              description: "Model must be one of: sonnet, opus, haiku, inherit"
            skills:
              type: array
              items:
                type: string
              description: "Optional list of skill names"
            tools:
              type: string
              description: "Optional comma-separated list of tool names"
          required:
            - name
            - description
            - model
      failure_message: "Agent file has invalid or missing YAML frontmatter"
      expected_behavior: "Agent files should have valid YAML frontmatter with name, description, and model fields (model must be: sonnet, opus, haiku, or inherit)"

    # Phase 2: Tools format validation
    - name: check_tools_format
      type: core:regex_match
      description: "Validate tools field uses comma-separated format on single line"
      params:
        pattern: '^tools:\s+[A-Za-z][\w_]+(?:,\s*[A-Za-z][\w_]+)*\s*$'
        flags: 8
      failure_message: "Agent tools field uses YAML list format (- Read) instead of comma-separated format"
      expected_behavior: "Tools should be comma-separated on one line: 'tools: Read, Write, Edit, Grep, Glob' not YAML list with dashes"

    # Phase 3: Description quality
    - name: check_description_quality
      type: prompt
      model: sonnet
      prompt: |
        TASK: Evaluate ONLY the agent description for quality and clarity.

        CRITICAL ISSUES to report:
        - Vague or generic descriptions lacking specificity
        - Missing activation context (when/why to use this agent)
        - No domain-specific terminology or trigger terms

        ACCEPTABLE patterns:
        - Action-oriented language describing what it does
        - Specific mentions of domains, tools, or technologies
        - Clear usage context ("Use when..." or "Specialized for...")

        Examples of GOOD descriptions:
        - Agents: "Specialized developer agent for implementing features in Drift project"
        - "Use when writing comprehensive pytest test suites with 90%+ coverage"
        - "Specialized CI/CD agent for automation and GitHub Actions workflows"

        Examples of BAD descriptions:
        - "Helps with testing" (too vague)
        - "Does stuff" (no specificity)
        - "A useful tool" (generic, no activation context)

        IMPORTANT - OUT OF SCOPE (do NOT analyze or report these):
        - File existence or missing files - NOT YOUR JOB
        - Resource file links - NOT YOUR JOB
        - Duplicate files - NOT YOUR JOB
        - MCP tool references - NOT YOUR JOB
        - Project-specific context - NOT YOUR JOB
        - Documentation completeness - NOT YOUR JOB
        - YAML code examples - NOT YOUR JOB
        - Template content - NOT YOUR JOB
        - Skills/tools relationship - Skills are auto-loaded, they don't need the Skill tool - NOT YOUR JOB
        - Whether tools list includes Skill tool - NOT YOUR JOB
        - Frontmatter fields relationships - NOT YOUR JOB

        Your ONLY task: Is the description clear and specific?

        Only report CRITICAL issues. Ignore minor style preferences.
      available_resources:
        - agent

    # Phase 4: Workflow quality
    - name: check_workflow_quality
      type: prompt
      model: sonnet
      prompt: |
        Evaluate if agent provides adequate workflow guidance per Anthropic best practices.

        A GOOD agent definition includes:
        - Clear role and expertise statement
        - Step-by-step process (numbered workflow)
        - Specific actions to take when invoked
        - What to check, verify, or deliver

        CRITICAL ISSUES (report these):
        - Agent has NO role/expertise explanation
        - Agent provides NO process or workflow steps
        - Agent is completely missing actionable guidance

        Examples of GOOD workflow guidance:
        - "When invoked: 1. Run git diff 2. Focus on modified files 3. Begin review"
        - "Process: 1. Read requirements 2. Design test cases 3. Implement with pytest"
        - "Steps: 1. Analyze logs 2. Identify root cause 3. Propose fixes"

        Examples of BAD (report these):
        - No workflow section at all
        - Only vague statements like "Help with tasks"
        - No clear process or steps

        Focus: Does the agent tell Claude HOW to do the work?
      available_resources:
        - agent

    # Phase 5: Check broken links
    - name: check_broken_links
      type: core:markdown_link
      description: "Check for broken links in agent documentation"
      failure_message: "Found broken links in agents"
      expected_behavior: "All file references and links should be valid"
      params:
        check_local_files: true
        check_external_urls: false
        skip_code_blocks: true
        custom_skip_patterns:
          - '\.py'
          - '\.yaml'
          - '\.yml'
          - '\.cfg'
          - '\.json'  # Skip JSON files (often placeholders like log.json)
          - 'CHANGELOG\.md'
          - 'github/workflows/'

    # Phase 6: Check duplicate dependencies
    - name: check_duplicate_dependencies
      type: core:dependency_duplicate
      description: "Check for redundant transitive dependencies in agents"
      failure_message: "Found redundant dependency: {duplicate_resource}"
      expected_behavior: "Agents should only declare direct dependencies, not transitive ones"
      params:
        resource_dirs:
          - .claude/agents
          - .claude/skills

    # Phase 7: Verify references
    - name: verify_references
      type: prompt
      model: sonnet
      prompt: |
        Check if agent frontmatter declares skills or agents that don't exist.

        Project context shows available skills. Check frontmatter "skills: [...]" array.

        ONLY report:
        - Frontmatter declares skill that doesn't exist in .claude/skills/
        - Frontmatter references agent that doesn't exist in .claude/agents/

        DO NOT check or report:
        - References to project scripts or tools (./test.sh, ./lint.sh)
        - MCP server references (if server is in project context)
        - Documentation links or examples
        - Tool names in the tools field

        Focus: Do frontmatter skill/agent declarations exist?
      available_resources:
        - agent
        - skill

    # Phase 8: Final quality check
    - name: final_quality_check
      type: prompt
      model: sonnet
      prompt: |
        Review all findings from previous validation phases for this agent.

        ONLY report if there are CRITICAL structural problems that would prevent the agent from functioning:
        - Missing required frontmatter fields
        - Broken references to non-existent dependencies
        - Contradictory instructions
        - Completely missing or empty required sections

        IGNORE and do NOT report:
        - Minor formatting preferences
        - Style suggestions
        - Optional improvements
        - Subjective quality opinions

        If all critical issues were already caught by earlier phases, report: "No additional critical issues found."
      available_resources:
        - agent
        - skill

# ==============================================================================
# COMMAND VALIDATION
# ==============================================================================
command_validation:
  description: "Comprehensive validation for Claude Code commands"
  scope: project_level
  context: "Commands must be clear, consistent, and maintainable. This rule validates frontmatter, execution clarity, and dependencies."
  requires_project_context: true
  supported_clients:
    - claude-code
  document_bundle:
    bundle_type: command
    file_patterns:
      - .claude/commands/*.md
    bundle_strategy: individual
    resource_patterns: []
  phases:
    # Phase 1: Frontmatter validation
    - name: check_frontmatter
      type: core:yaml_frontmatter
      params:
        required_fields:
          - description
        schema:
          type: object
          properties:
            description:
              type: string
              minLength: 10
              description: "Command description must be at least 10 characters"
            skills:
              type: array
              items:
                type: string
              description: "Optional list of skill names to activate"
            argument-hint:
              oneOf:
                - type: string
                - type: array
                  items:
                    type: string
              description: "Optional hint(s) for command arguments during tab-completion"
          required:
            - description
      failure_message: "Command file has invalid or missing YAML frontmatter"
      expected_behavior: "Command files should have valid YAML frontmatter with a description field"

    # Phase 2: Parameter hints check
    - name: check_parameter_hints
      type: prompt
      model: sonnet
      prompt: |
        TASK: Check ONLY if command uses parameters but is missing argument-hint.

        CRITICAL ISSUES (report these):
        1. Command content includes $ARGUMENTS, $1, $2, $3, etc. but frontmatter has NO argument-hint field
        2. Command clearly expects parameters (mentions "<parameter>" or "pass <value>") but no argument-hint

        ACCEPTABLE (do NOT report):
        - Command has argument-hint field for parameters ✓
        - Command doesn't use any parameters (no $ARGUMENTS, $1, etc.) ✓
        - Command references files with @ syntax but doesn't take parameters ✓

        IMPORTANT - OUT OF SCOPE (do NOT analyze or report these):
        - File existence or missing files - NOT YOUR JOB
        - Resource file links - NOT YOUR JOB
        - Duplicate files - NOT YOUR JOB
        - MCP tool references - NOT YOUR JOB
        - MCP tool availability - NOT YOUR JOB
        - Project-specific context - NOT YOUR JOB
        - Documentation completeness - NOT YOUR JOB
        - Execution instructions - NOT YOUR JOB
        - Command clarity - NOT YOUR JOB

        Your ONLY task: Does the command use parameters but lack argument-hint?

        REASONING: argument-hint helps users during tab-completion. If a command takes parameters,
        it should guide users on what to provide.
      available_resources:
        - command

    # Phase 3: Verify all references
    - name: verify_all_references
      type: prompt
      model: sonnet
      prompt: |
        Verify all references in the command file comprehensively.

        Project context shows available skills and commands.

        ONLY report:
        - Frontmatter declares skill that doesn't exist in .claude/skills/
        - Documentation references command that doesn't exist in .claude/commands/
        - Documentation references agent that doesn't exist in .claude/agents/
        - Direct contradictions between commands (one says "always X", another says "never X")

        DO NOT check or report:
        - Project scripts (./test.sh, ./lint.sh are valid)
        - MCP tool names or syntax (if MCP server is configured)
        - Style differences between commands
        - Different approaches that aren't contradictory
        - Tool invocation syntax (Skill(), SlashCommand(), etc.)

        Focus: Do frontmatter declarations and documentation references exist?
      available_resources:
        - command
        - skill
        - agent

    # Phase 4: Description quality
    - name: check_description_quality
      type: prompt
      model: sonnet
      prompt: |
        Evaluate the command description for quality and clarity.

        CRITICAL ISSUES to report:
        - Vague or generic descriptions lacking specificity
        - Missing activation context (when/why to use this command)
        - No domain-specific terminology or trigger terms

        ACCEPTABLE patterns:
        - Action-oriented language describing what it does
        - Specific mentions of domains, tools, or technologies
        - Clear usage context for commands

        Examples of GOOD descriptions:
        - Commands: "Run comprehensive validation including tests and linting"
        - "Run pytest tests with coverage reporting"
        - "Create PR with quality validation"

        Examples of BAD descriptions:
        - "Helps with testing" (too vague)
        - "Does stuff" (no specificity)
        - "A useful tool" (generic, no activation context)

        Only report CRITICAL issues. Ignore minor style preferences.
      available_resources:
        - command

    # Phase 5: Execution clarity
    - name: check_execution_clarity
      type: prompt
      model: sonnet
      prompt: |
        Evaluate the command's execution clarity and usability.

        CRITICAL ISSUES (report these):
        - Command has NO purpose explanation anywhere
        - Command provides ZERO execution guidance (no steps at all)
        - Invocation syntax completely missing or totally unclear

        ACCEPTABLE (do NOT report):
        - References to project scripts (./test.sh, ./lint.sh)
        - References to MCP tools by name
        - Parameter placeholders like <issue_number>, $ARGUMENTS
        - Brief execution steps (some guidance is better than none)
        - Missing exhaustive success criteria (nice-to-have)

        ONLY REPORT if there's a REAL problem, not style nitpicks.
      available_resources:
        - command
        - skill
        - agent

    # Phase 6: Check broken links
    - name: check_broken_links
      type: core:markdown_link
      description: "Check for broken links in command documentation"
      failure_message: "Found broken links in commands"
      expected_behavior: "All file references and links should be valid"
      params:
        check_local_files: true
        check_external_urls: false
        skip_code_blocks: true
        custom_skip_patterns:
          - '\.py'
          - '\.yaml'
          - '\.yml'
          - '\.cfg'
          - '\.json'  # Skip JSON files (often placeholders like log.json)
          - 'CHANGELOG\.md'
          - 'github/workflows/'

    # Phase 7: Pattern consistency check
    - name: check_pattern_consistency
      type: prompt
      model: sonnet
      prompt: |
        Check if similar commands follow similar patterns for skill usage.

        CRITICAL ISSUES (report these):
        1. Testing-related commands (test, full-check, create-pr) have inconsistent use of "testing" skill
           → Some declare it, others don't (should be consistent)
        2. Linting-related commands have inconsistent use of "linting" skill
        3. GitHub-related commands have inconsistent use of "github-operations" skill
        4. Similar commands use different approaches without good reason

        ACCEPTABLE (do NOT report):
        - All test-related commands use "testing" skill ✓
        - All lint-related commands use "linting" skill ✓
        - Commands for different domains use different skills ✓ (expected)
        - One-off commands don't follow a pattern ✓ (no similar commands to compare)

        Focus: Do similar commands follow similar patterns for skill activation?
      available_resources: []

    # Phase 8: Check duplicate dependencies
    - name: check_duplicate_dependencies
      type: core:dependency_duplicate
      description: "Check for redundant transitive dependencies in commands"
      failure_message: "Found redundant dependency: {duplicate_resource}"
      expected_behavior: "Commands should only declare direct dependencies, not transitive ones"
      params:
        resource_dirs:
          - .claude/commands
          - .claude/skills

    # Phase 9: Check circular dependencies
    - name: check_circular_dependencies
      type: core:claude_circular_dependencies
      description: "Detect circular dependency cycles"
      params:
        resource_dirs:
          - .claude/commands
          - .claude/skills
          - .claude/agents
      failure_message: "Circular dependency detected: {circular_path}"
      expected_behavior: "Commands should not have circular skill dependencies"

    # Phase 10: Final quality check
    - name: final_quality_check
      type: prompt
      model: sonnet
      prompt: |
        Review all findings from previous validation phases for this command.

        ONLY report if there are CRITICAL structural problems that would prevent the command from functioning:
        - Missing required frontmatter fields
        - Broken references to non-existent dependencies
        - Contradictory instructions
        - Completely missing or empty required sections

        IGNORE and do NOT report:
        - Minor formatting preferences
        - Style suggestions
        - Optional improvements
        - Subjective quality opinions

        If all critical issues were already caught by earlier phases, report: "No additional critical issues found."
      available_resources:
        - command
        - skill
        - agent

# ==============================================================================
# RULE VALIDATION
# ==============================================================================
rule_validation:
  description: "Comprehensive validation for Claude Code rules"
  scope: project_level
  context: "Rules define project standards following Claude Code's best practices. Each rule must be focused, well-named, and provide clear validation criteria."
  requires_project_context: true
  supported_clients:
    - claude-code
  document_bundle:
    bundle_type: rule
    file_patterns:
      - .claude/rules/*.md
    bundle_strategy: individual
    resource_patterns: []
  phases:
    # Phase 1: Check frontmatter exists and is valid
    - name: check_frontmatter
      type: core:yaml_frontmatter
      params:
        required_fields:
          - name
          - description
        schema:
          type: object
          properties:
            name:
              type: string
              pattern: "^[a-z][a-z0-9-]*$"
              description: "Rule name in kebab-case"
            description:
              type: string
              minLength: 10
              description: "One-sentence description of what this rule validates"
            path:
              type: string
              description: "Optional glob pattern for files this rule applies to (e.g., '**/*.py', 'tests/**/*.py')"
          required:
            - name
            - description
      failure_message: "Rule file has invalid or missing frontmatter"
      expected_behavior: "Rules must have 'name' and 'description' fields in YAML frontmatter. Optional 'path' field can specify which files the rule applies to."

    # Phase 2: Check for broken links
    - name: check_broken_links
      type: core:markdown_link
      params:
        check_local_files: true
        check_external_urls: false
        skip_code_blocks: true
        custom_skip_patterns:
          - '\.py'
          - '\.yaml'
      failure_message: "Found broken links in rule file"
      expected_behavior: "All file references should be valid"

    # Phase 3: Check rule follows best practices
    - name: check_best_practices
      type: prompt
      model: sonnet
      prompt: |
        Evaluate if this rule file follows Claude Code best practices.

        CRITICAL ISSUES (report these):
        1. **Multiple UNRELATED topics in one file**: Rule covers topics that would be used in completely different contexts
           - Example BAD: File covers imports AND testing (different workflows)
           - Example BAD: File covers git commits AND Python formatting (different domains)
           - Example GOOD: File covers prohibited language AND citation requirements (both about documentation quality)
           - Example GOOD: File covers version format AND tag format AND changelog rules (all about releases)

        2. **Vague filename**: Filename doesn't clearly indicate what rule covers
           - Example BAD: "standards.md", "rules.md", "python.md"
           - Example GOOD: "python-imports.md", "test-coverage.md", "git-commits.md"

        3. **Contains HOW-TO content**: Shows workflows or step-by-step processes (belongs in skills)
           - Example BAD: "Run pytest with these flags...", "Here's how to organize imports..."
           - Example GOOD: "MUST have 90% coverage", "MUST place imports at top"

        ACCEPTABLE (do NOT report):
        - Single focused domain/topic with multiple related aspects
        - Related constraints that work together (e.g., all documentation quality rules together)
        - Different facets of the same concern (e.g., prohibited terms + required citations = documentation standards)
        - Clear MUST/MUST NOT statements
        - Specific thresholds (90% coverage, 100 char line length)
        - Rationale sections explaining why
        - Brief examples showing WHAT is required (not HOW to achieve it)

        Focus: Does this rule cover ONE cohesive topic/domain, or multiple UNRELATED topics that should be separate?
      available_resources:
        - rule

    # Phase 4: Semantic quality check
    - name: check_rule_quality
      type: prompt
      model: sonnet
      prompt: |
        Analyze this rule file for quality.

        CRITICAL ISSUES (report these):
        1. Vague requirements without specifics (e.g., "code should be good")
        2. No clear success criteria or measurable standards
        3. Missing rationale for important constraints
        4. Instructional/workflow rules instead of declarative standards:
           - WRONG: "MUST verify recommendations against official docs" (tells AI what to DO)
           - WRONG: "MUST update documentation for changes" (tells AI a workflow step)
           - WRONG: "Implementation is source of truth" (tells AI where to check)
           - WRONG: "Test-driven validation" (tells AI HOW to work)
           - RIGHT: "MUST follow PEP 8" (declarative standard about code)
           - RIGHT: "MUST have 90% coverage" (measurable threshold)
           - RIGHT: "MUST NOT use subjective language like 'easily'" (declarative standard about content)
        5. MCP tool references (e.g., "Use mcp__context7", "Use mcp__serena", "Use mcp__github")
           - These are AI-specific instructions that belong in skills/agents/commands

        Rules should describe what the FINAL ARTIFACT looks like, not what the AI should do during work.
        Workflow instructions belong in skills/agents/commands, not rules.

        ACCEPTABLE (do NOT report):
        - Declarative standards about code/docs (e.g., "MUST use snake_case")
        - Specific thresholds (90% coverage, 100 char line length)
        - Forbidden patterns with examples (e.g., "MUST NOT use: easily, simply, just")
        - Format requirements (e.g., "Commit messages MUST be under 72 characters")
        - What the artifact MUST/MUST NOT contain

        Focus: Does this describe what the final artifact should BE, or does it tell the AI what to DO?
      available_resources:
        - rule

# ==============================================================================
# CLAUDE.MD VALIDATION
# ==============================================================================
claude_md_validation:
  description: "Comprehensive validation for CLAUDE.md configuration file"
  scope: project_level
  context: "CLAUDE.md provides essential context for Claude Code about project structure and conventions. It must exist, be concise, follow best practices, and document key components."
  requires_project_context: true
  supported_clients:
    - claude-code
  document_bundle:
    bundle_type: mixed
    file_patterns:
      - CLAUDE.md
    bundle_strategy: collection
    resource_patterns: []
  phases:
    # Phase 1: File existence
    - name: check_file_exists
      type: core:file_exists
      params:
        file_path: CLAUDE.md
      failure_message: "CLAUDE.md file is missing from project root"
      expected_behavior: "Project should have CLAUDE.md file documenting structure and conventions"

    # Phase 2: Line count check
    - name: check_line_count
      type: core:file_size
      params:
        file_path: CLAUDE.md
        max_count: 300
      failure_message: "CLAUDE.md exceeds 300 lines (best practice for concise context)"
      expected_behavior: "CLAUDE.md should be concise and under 300 lines"

    # Phase 3: Check code blocks aren't too long
    - name: check_code_blocks_concise
      type: core:block_line_count
      description: "Ensure code examples in CLAUDE.md are concise"
      params:
        pattern_start: "^```"
        pattern_end: "^```"
        max_lines: 20
        files:
          - "CLAUDE.md"
      failure_message: "Code block at CLAUDE.md:{line_start}-{line_end} has {actual_count} lines (expected at most {threshold})"
      expected_behavior: "Code examples in CLAUDE.md should be brief (max 20 lines) to keep context concise"

    # Phase 4: Content quality
    - name: check_content_quality
      type: prompt
      model: sonnet
      prompt: |
        Evaluate CLAUDE.md for content quality and anti-patterns per Anthropic best practices.

        CRITICAL ISSUES (report these):

        **Conciseness**:
        1. Large narrative paragraphs (>8 consecutive non-bullet/non-list lines of plain text) instead of bullet points
           → Note: Bullet list items CAN have 1-2 sentence descriptions - that's acceptable
           → Only flag if there are 8+ lines of continuous paragraph text with NO bullets/numbers

        **Completeness & Structure**:
        2. Missing ALL essential sections: tech stack, architecture, key commands/workflows, and coding standards
        3. No clear Markdown structure (no headers at all, completely unorganized)
        4. File is empty or only contains generic template boilerplate with no project-specific info

        **Anti-Patterns**:
        5. Contains detailed linting/formatting rules (e.g., "max line length 88", "import order: stdlib, third-party, local")
           → Should use automated tools (pyproject.toml, .flake8) NOT CLAUDE.md
        6. Embeds full API documentation (>30 lines of endpoint specs, schemas, or API reference)
           → Should link to API docs instead
        7. Session-specific instructions (e.g., "In this conversation..." or "For today's task...")
           → CLAUDE.md must be universal across all sessions

        ACCEPTABLE (do NOT report):
        - Brief narrative intros (2-3 sentences) before bullet lists
        - Bullet/numbered list items with 1-2 sentence descriptions (this is NOT a narrative paragraph)
        - Variations in section naming ("Tech Stack" vs "Stack")
        - Brief sections (concise is good)
        - Missing optional sections like "Contributing"
        - Sections combined logically ("Commands & Workflows")
        - Brief style references ("We follow PEP 8, see pyproject.toml") ✓
        - Links to API docs ✓
        - General universal guidelines ✓
        - Brief code examples (2-3 lines) ✓

        EXAMPLES OF ACCEPTABLE:
        - "Stack: Python 3.11, FastAPI" ✓ (brief)
        - "Use black/flake8. Config in pyproject.toml" ✓ (pointer)
        - "API docs: https://example.com/api" ✓ (link)
        - "1. **Project Validation**: Fast checks for docs. Zero API calls." ✓ (list item with description)
        - "- **Anthropic API**: Set ANTHROPIC_API_KEY" ✓ (bullet with description)

        EXAMPLES TO FLAG:
        - "Linting: max-line-length=88, import order: stdlib, third-party..." ✗ (detailed rules)
        - 50-line API endpoint specification section ✗ (embedded docs)
        - "In this conversation, focus on auth module" ✗ (session-specific)
        - 12-line paragraph explaining commands ✗ (use bullets)
        - Multiple "TODO: add your..." with no actual content ✗ (template only)

        ONLY REPORT issues that significantly impact quality or violate best practices.
      available_resources: []

    # Phase 5: Import syntax check
    - name: check_import_syntax
      type: prompt
      model: sonnet
      prompt: |
        Check CLAUDE.md for proper import syntax usage per Claude Code documentation.

        CRITICAL ISSUES (report these):
        1. Import syntax @path/to/file used INSIDE code blocks (```...```)
           → Imports must be outside code blocks to be processed
        2. Deeply nested imports exceeding 5 hops
           → Per docs: "imports should not exceed 5 hops in depth"

        ACCEPTABLE (do NOT report):
        - @path/to/file imports outside code blocks ✓ (correct usage)
        - Import depth ≤ 5 hops ✓ (within limits)
        - No imports used ✓ (imports are optional)
        - File paths in code examples (not using @ syntax) ✓

        REASONING: Claude Code's import feature has specific requirements:
        - Must be outside code blocks to be processed
        - Deep nesting (>5 hops) impacts performance

        Focus: Are imports used correctly if present?
      available_resources: []

    # Phase 6: Component documentation check
    - name: check_component_documentation
      type: prompt
      model: sonnet
      prompt: |
        Check if CLAUDE.md documents the key Claude Code components in this project.

        You have access to:
        - CLAUDE.md content
        - All agent files (.claude/agents/*.md)
        - All skill files (.claude/skills/*/SKILL.md)
        - All command files (.claude/commands/*.md)

        CRITICAL ISSUES (report these):
        1. CLAUDE.md doesn't mention ANY agents (should list all agents in .claude/agents/)
        2. CLAUDE.md doesn't mention ANY slash commands (should document key commands from .claude/commands/)
        3. CLAUDE.md completely omits the Claude Code setup section (no .claude/ mention at all)

        ACCEPTABLE (do NOT report):
        - CLAUDE.md lists all agents ✓
        - CLAUDE.md documents major commands (doesn't need every single one, but key workflows) ✓
        - CLAUDE.md mentions key skills (doesn't need exhaustive list, just important ones) ✓
        - CLAUDE.md explains where to find more detail (.claude/ directory structure) ✓
        - Some minor or internal-only commands omitted (acceptable)

        EXAMPLES:

        GOOD (do NOT report):
        - Lists all 3 agents: cicd, developer, qa ✓
        - Documents key commands: /test, /lint, /full-check, /create-pr ✓
        - Mentions major skills: testing, linting, code-review ✓

        BAD (report these):
        - Has 4 agents but only lists 3 ✗ (missing documentation agent)
        - No commands documented anywhere ✗ (users can't discover them)
        - No mention of .claude/ setup at all ✗ (missing context)

        Focus: Are major components discoverable through CLAUDE.md?
      available_resources: []

# ==============================================================================
# CLAUDE SETTINGS VALIDATION
# ==============================================================================
claude_settings_validation:
  description: "Validation for Claude Code settings.json configuration"
  scope: project_level
  context: "The .claude/settings.json file must properly configure permissions for skills and MCP servers. Missing or duplicate entries prevent proper tool usage."
  requires_project_context: true
  supported_clients:
    - claude-code
  phases:
    # Phase 1: Skill permissions check
    - name: check_skill_permissions
      type: core:claude_skill_settings
      failure_message: "Skills missing from .claude/settings.json permissions.allow array"
      expected_behavior: "Every skill directory in .claude/skills/ should have a corresponding Skill(name) entry in .claude/settings.json"

    # Phase 2: MCP permissions check
    - name: check_mcp_permissions
      type: core:claude_mcp_permissions
      failure_message: "MCP servers missing from .claude/settings.json permissions.allow array"
      expected_behavior: "Every MCP server in .mcp.json should have a corresponding MCP(server-name) entry in .claude/settings.json"

    # Phase 3: Duplicate permissions check
    - name: check_duplicate_permissions
      type: core:claude_settings_duplicates
      failure_message: "Duplicate permission entries found in .claude/settings.json"
      expected_behavior: "All permission entries in .claude/settings.json permissions.allow should be unique"
