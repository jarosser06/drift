# Drift Configuration for drift project
# This file defines custom drift learning types specific to this project

providers:
  bedrock:
    provider: bedrock
    params:
      region: us-east-1

models:
  haiku:
    provider: bedrock
    model_id: us.anthropic.claude-haiku-4-5-20251001-v1:0
  sonnet:
    provider: bedrock
    model_id: us.anthropic.claude-sonnet-4-5-20250929-v1:0

default_model: haiku

agent_tools:
  claude-code:
    conversation_path: ~/.claude/projects/
    enabled: true

conversations:
  mode: latest
  days: 7

temp_dir: /tmp/drift

drift_learning_types:
  # Conversation-level behavioral patterns
  incomplete_work:
    description: "AI stopped before completing the full scope of work"
    scope: conversation_level
    context: "AI stopping before completing full scope wastes user time and breaks workflow momentum. Clear completion expectations improve efficiency."
    requires_project_context: false
    phases:
      - name: detection
        model: haiku
        prompt: |
          Look for instances where the AI claimed to be done but the user had to ask for completion, finishing touches, or missing parts.

          Focus on these patterns:
          - AI marking tasks as complete when significant work remains
          - User asking "what about..." or "you didn't finish..." after AI claims completion
          - Missing deliverables that were part of the original request

          Explicit phrases that indicate this drift:
          - "Finish", "Complete", "You didn't finish"
          - "What about", "You missed", "Still need"

          Behavioral patterns to look for:
          - User lists missing items after AI says done
          - User asks for specific parts AI didn't do
          - AI says 'done' but user continues with 'also need'

          Example:
          User requests "implement auth", AI adds login only, then user asks "what about logout and session handling?"
        available_resources: []

  agent_delegation_miss:
    description: "AI performed tasks that available agents could handle better"
    scope: conversation_level
    context: "Identifies when AI performs tasks that available agents could handle better, leading to slower workflows and inconsistent results. Proper delegation improves speed and reliability."
    requires_project_context: true
    supported_clients:
      - claude-code
    phases:
      - name: detection
        model: haiku
        prompt: |
          Identify when AI performs tasks that available agents could handle better, leading to slower workflows and inconsistent results.

          When analyzing, consider which agents are available in the project (if project context is provided).

          Focus on these patterns:
          - AI manually performing tasks that specialized agents could automate
          - User suggesting "use the X agent" or "let the agent handle this"
          - AI spending multiple turns on tasks an agent could complete in one
          - Repetitive manual work that agents are designed for

          Explicit phrases that indicate this drift:
          - "Use the agent", "Let the agent handle"
          - "Why didn't you use the agent", "Delegate to"

          Behavioral patterns to look for:
          - AI manually performs automated tasks
          - User redirects to agent-based workflow
          - Multiple turns for single-agent task

          Example:
          User says "run tests", AI manually searches for test files and reads them, then user says "just use the testing agent"
        available_resources: []

  skill_ignored:
    description: "AI reinvented solutions when documented skills existed"
    scope: conversation_level
    context: "Reinventing documented solutions creates inconsistency and wastes development time. Using existing skills ensures proven patterns."
    requires_project_context: true
    supported_clients:
      - claude-code
    phases:
      - name: detection
        model: haiku
        prompt: |
          Find cases where AI implemented functionality from scratch when project skills already documented the approach.

          When analyzing, consider which skills are available in the project (if project context is provided).

          Focus on these patterns:
          - AI writing code that duplicates skill patterns
          - User pointing to "we have a skill for this"
          - AI not following documented skill workflows
          - User referencing skill documentation AI should have used

          Explicit phrases that indicate this drift:
          - "We have a skill for", "Check the skill"
          - "Follow the skill pattern", "Use the documented approach"

          Behavioral patterns to look for:
          - AI implements from scratch when skill exists
          - User references skill documentation
          - Deviation from documented workflow

          Example:
          User asks "add API endpoint", AI writes custom code, then user says "we have a REST API skill that shows the pattern"
        available_resources: []

  workflow_bypass:
    description: "User manually prompted instead of using documented workflows"
    scope: conversation_level
    context: "Manual prompting instead of documented workflows misses validation steps and efficiency gains. Following established processes ensures quality and speed."
    requires_project_context: false
    phases:
      - name: detection
        model: haiku
        prompt: |
          Detect when user bypassed documented workflows, commands, or processes by manually prompting the AI. This indicates workflows may need improvement or the user isn't aware of them.

          Focus on these patterns:
          - User manually describing multi-step processes that commands automate
          - Conversation following manual path when slash command exists
          - User unaware of available automation
          - Missing validation steps that workflows would provide

          Explicit phrases that indicate this drift:
          - "I didn't know there was a command"
          - "Oh, there's a workflow for that"
          - "Should have used the command"

          Behavioral patterns to look for:
          - User manually describes automated workflow
          - Missing validation from standard workflow
          - Conversation recreates command functionality

          Example:
          User says "first run tests, then lint, then build, then commit" when a /full-check command exists that does all of this

          Note: Maximum 1 learning per conversation for this type.
        available_resources: []

  prescriptive_deviation:
    description: "AI interpreted or improvised when literal adherence was required"
    scope: conversation_level
    context: "AI creativity is valuable, but some contexts require exact adherence to documented patterns for consistency and compliance."
    requires_project_context: false
    phases:
      - name: detection
        model: haiku
        prompt: |
          Identify when AI added creativity or interpretation to tasks requiring exact adherence to documented patterns, specifications, or requirements.

          Focus on these patterns:
          - User corrections: "exactly as shown", "don't change anything", "follow it literally"
          - AI paraphrasing when quoting was required
          - AI improving/optimizing when copying was needed
          - Context requiring compliance (regulations, specs, established patterns)

          Explicit phrases that indicate this drift:
          - "Exactly as shown", "Literally"
          - "Don't change anything", "Copy it exactly"
          - "Follow it precisely"

          Behavioral patterns to look for:
          - User corrects AI's interpretation
          - AI paraphrased when quoting needed
          - AI optimized when copying required

          Example:
          User says "add the error message from the spec", AI writes similar message, then user says "no, use the exact wording from the spec"
        available_resources: []

  command_activation_required:
    description: "AI failed to activate required skills before executing slash command steps"
    scope: conversation_level
    context: "Commands with required skills dependencies must have those skills activated first to ensure proper execution context and tooling availability."
    requires_project_context: true
    supported_clients:
      - claude-code
    phases:
      - name: initial_analysis
        model: sonnet
        prompt: |
          Analyze the conversation to identify if any slash commands were executed.
          If you need more information about specific commands, request:
          - command: The specific slash command that was executed
        available_resources:
          - command
          - skill
          - main_config
      - name: verify_dependencies
        model: sonnet
        prompt: |
          Check if the identified command has "Required skills:" specified.
          Request command or skill resources if needed to verify dependencies.
        available_resources:
          - command
          - skill
          - main_config
      - name: final_determination
        model: sonnet
        prompt: |
          Make final determination: Did the AI activate all required skills before executing the command steps?
          If yes, return no findings. If no, return a finding with observed and expected behavior.
        available_resources:
          - command
          - skill
          - main_config

  no_agents_configured:
    description: "Project has no agents configured, missing automation opportunities"
    scope: conversation_level
    context: "Projects without agents miss opportunities for specialized task delegation and workflow optimization. Adding agents for common tasks improves speed and consistency."
    requires_project_context: true
    supported_clients:
      - claude-code
    phases:
      - name: detection
        model: haiku
        prompt: |
          Determine if the project has zero agents configured. This is a project-level issue indicating missed opportunities for task delegation and workflow automation.

          Based on the project context (if provided), check if any agents are configured.

          If no agents are found, this represents an opportunity to add specialized agents for common tasks to improve workflow speed and consistency.

          Behavioral patterns to look for:
          - No agents configured in project
          - Project context shows empty agents list
          - Project with .claude/ directory but no .claude/agents/ folder

          Note: Maximum 1 learning per conversation for this type.
        available_resources: []

  # Project-level document analysis
  skill_completeness:
    description: "Claude Code skills missing essential components or clarity"
    scope: project_level
    context: "Incomplete skills create confusion and slow development. Skills must be self-contained with clear examples and dependencies."
    requires_project_context: true
    supported_clients:
      - claude-code
    document_bundle:
      bundle_type: skill
      file_patterns:
        - .claude/skills/*/SKILL.md
      bundle_strategy: individual
      resource_patterns:
        - "**/*.py"
        - "**/*.js"
        - "**/*.md"
        - "**/*.ts"
    phases:
      - name: basic_structure
        model: sonnet
        prompt: |
          Check if the skill has basic structure: clear title, purpose, examples.
          Look for obvious missing components or vague instructions.
        available_resources:
          - skill
      - name: verify_dependencies
        model: sonnet
        prompt: |
          If the skill references other skills, verify they exist by requesting them.
          Check if "Required skills:" section is present when needed.
        available_resources:
          - skill
      - name: final_quality_check
        model: sonnet
        prompt: |
          Make final determination on skill quality.
          Report any issues with observed behavior and expected quality standards.
        available_resources:
          - skill

  agent_completeness:
    description: "Claude Code agents missing essential components or clarity"
    scope: project_level
    context: "Incomplete agents create confusion about delegation and task automation. Agents must clearly define their scope and dependencies."
    requires_project_context: true
    supported_clients:
      - claude-code
    document_bundle:
      bundle_type: agent
      file_patterns:
        - .claude/agents/*.md
      bundle_strategy: individual
      resource_patterns: []
    phases:
      - name: basic_structure
        model: sonnet
        prompt: |
          Check if the agent has basic structure: clear purpose, tool declarations, examples.
          Look for obvious missing components or vague task descriptions.
        available_resources:
          - agent
      - name: verify_references
        model: sonnet
        prompt: |
          If the agent references other agents, verify they exist by requesting them.
        available_resources:
          - agent
      - name: final_quality_check
        model: sonnet
        prompt: |
          Make final determination on agent quality.
          Report any issues with observed behavior and expected quality standards.
        available_resources:
          - agent

  command_completeness:
    description: "Claude Code commands missing essential components or clarity"
    scope: project_level
    context: "Incomplete commands miss validation steps and create workflow inefficiency. Commands must declare dependencies and provide clear execution steps."
    requires_project_context: true
    supported_clients:
      - claude-code
    document_bundle:
      bundle_type: command
      file_patterns:
        - .claude/commands/*.md
      bundle_strategy: individual
      resource_patterns: []
    phases:
      - name: basic_structure
        model: sonnet
        prompt: |
          Check if the command has basic structure: clear purpose, execution steps, examples.
          Look for missing "Required skills:" section or vague instructions.
        available_resources:
          - command
          - skill
          - agent
      - name: verify_dependencies
        model: sonnet
        prompt: |
          If the command references other commands, skills, or agents, verify they exist.
          Request command, skill, or agent resources as needed.
        available_resources:
          - command
          - skill
          - agent
      - name: final_quality_check
        model: sonnet
        prompt: |
          Make final determination on command quality and completeness.
          Report any issues with observed behavior and expected quality standards.
        available_resources:
          - command
          - skill
          - agent

  command_consistency:
    description: "Commands contradict project guidelines or each other"
    scope: project_level
    context: "Contradictory commands create confusion and workflow inefficiency. Commands must be consistent with project guidelines and declare their dependencies."
    requires_project_context: true
    supported_clients:
      - claude-code
    document_bundle:
      bundle_type: mixed
      file_patterns:
        - .claude/commands/*.md
        - CLAUDE.md
      bundle_strategy: collection
      resource_patterns: []
    phases:
      - name: detection
        model: haiku
        prompt: |
          Analyze these command documents for consistency and contradictions.

          Project root: {project_root}

          Files being analyzed:
          {files_with_paths}

          Focus on these patterns:
          - Commands that contradict CLAUDE.md guidelines
          - Inconsistent parameter naming across commands
          - Conflicting approaches to similar tasks
          - Commands referencing skills/agents that don't exist
          - Different terminology for the same concepts
          - Missing "Required skills:" declarations

          When reporting contradictions, cite specific files and conflicting content.

          Example contradictions:
          - Command A says "always run tests first" but Command B runs lint first
          - One command uses --force flag, another uses --skip-checks for same purpose
          - CLAUDE.md says use skill X, but command implements custom solution
          - Command requires skill but doesn't declare it
        available_resources: []

  claude_md_missing:
    description: "Project missing CLAUDE.md configuration file"
    scope: project_level
    context: "CLAUDE.md provides essential context for Claude Code about project structure and conventions. Missing this file reduces AI effectiveness."
    requires_project_context: true
    supported_clients:
      - claude-code
    phases:
      - name: check_file
        type: file_exists
        file_path: CLAUDE.md
        failure_message: "CLAUDE.md file is missing from project root"
        expected_behavior: "Project should have CLAUDE.md file documenting structure and conventions"
